dwplot(rbind(rm9, rm10, rm11, rm12),
vline = geom_vline(
xintercept = 0,
colour = "grey60",
linetype = 2
)) %>%
relabel_predictors(names_coef) +
theme_bw() +
xlab("Coefficient Estimate") +
scale_color_gb(reverse = TRUE) +
theme(text = element_text(family='SimSun', face = "bold", colour = "black"), axis.title.x = element_text(family='Times'))
}
ggsave("../figures/new_figure4.png", plot_DoEs, device = cairo_pdf, width = 8, height = 4.5)
ggsave("../figures/new_figure4.png")
knitr::include_graphics("../figures/figure4.png")
plot_DoEs <- {
dwplot(rbind(rm9, rm10, rm11, rm12),
vline = geom_vline(
xintercept = 0,
colour = "grey60",
linetype = 2
)) %>%
relabel_predictors(names_coef) +
theme_bw() +
xlab("Coefficient Estimate") +
scale_color_gb(reverse = TRUE) +
theme(text = element_text(family='SimSun', face = "bold", colour = "black"), axis.title.x = element_text(family='Times'))
}
{
dwplot(rbind(rm9, rm10, rm11, rm12),
vline = geom_vline(
xintercept = 0,
colour = "grey60",
linetype = 2
)) %>%
relabel_predictors(names_coef) +
theme_bw() +
xlab("Coefficient Estimate") +
scale_color_gb(reverse = TRUE) +
theme(text = element_text(family='SimSun', face = "bold", colour = "black"), axis.title.x = element_text(family='Times'))
}
ggsave(plot_DoEs, "../figures/new_figure4.png", width = 8, height = 4.5)
plot_DoEs <- {
dwplot(rbind(rm9, rm10, rm11, rm12),
vline = geom_vline(
xintercept = 0,
colour = "grey60",
linetype = 2
)) %>%
relabel_predictors(names_coef) +
theme_bw() +
xlab("Coefficient Estimate") +
scale_color_gb(reverse = TRUE) +
theme(text = element_text(family='SimSun', face = "bold", colour = "black"), axis.title.x = element_text(family='Times'))
}
ggsave(plot_DoEs, "../figures/new_figure4.png", width = 8, height = 4.5)
?ggsave
R.Version()
xaringan:::inf_mr()
xaringan:::inf_mr()
xaringan:::inf_mr()
xaringan:::inf_mr()
knitr::opts_chunk$set(echo = FALSE,
message = FALSE,
warning = FALSE)
htmltools::tagList(rmarkdown::html_dependency_font_awesome())
if (!require(pacman)) install.packages("pacman")
library(pacman)
p_load(
flextable, gridExtra,
knitr, # dependency
rvest, stringr, broom, jiebaR, tidytext, tidyverse
) # data wrangling # data wrangling
xaringanExtra::use_xaringan_extra(c("tile_view", # O
"broadcast",
"panelset",
"tachyons"))
# Functions preload
set.seed(313)
ls_zhongsheng <- read_html("http://politics.people.com.cn/GB/8198/426918/index.html") %>% # index page
html_nodes("h5 a") %>% # the nodes of the links
html_attr("href") %>% # just the links
str_replace("^/n1", "http://politics.people.com.cn/n1")
ls_zhongsheng <- read_html("http://politics.people.com.cn/GB/8198/426918/index.html") %>% # index page
html_nodes("h5 a") %>% # the nodes of the links
html_attr("href") %>% # just the links
str_replace("^/n1", "http://politics.people.com.cn/n1")
ls_zhongsheng <- read_html("http://politics.people.com.cn/GB/8198/426918/index.html") %>% # index page
html_nodes("h5 a") %>% # the nodes of the links
html_attr("href") %>% # just the links
str_replace("^/n1", "http://politics.people.com.cn/n1")
ls_zhongsheng <- read_html("http://politics.people.com.cn/GB/8198/426918/index.html") %>% # index page
html_nodes("h5 a") %>% # the nodes of the links
html_attr("href") %>% # just the links
str_replace("^/n1", "http://politics.people.com.cn/n1")
zs_article <- read_html(link, encoding = "GB18030") # read the html
df_zhongsheng <- map_df(ls_zhongsheng, function(link) {
zs_article <- read_html(link, encoding = "GB18030") # read the html
zs_time <- html_nodes(zs_article, ".box01 .fl") %>%
html_text %>%
str_extract("\\d{4}年\\d{2}月\\d{2}日")
zs_content <- html_nodes(zs_article, "#rwb_zw p") %>%
html_text %>%
str_c(collapse = "") %>% # combined the paragraphs
str_remove_all("\\s|\\n|\\t") # remove the horizontal spaces
zs_data <- data.frame(title = zs_title,
time = zs_time,
content = zs_content) %>%
mutate(
time = str_replace(time, "(\\d{4})年(\\d{2})月(\\d{2})日", "\\1-\\2-\\3"),
time = as.Date(time)
)
})
df_zhongsheng <- map_df(ls_zhongsheng, function(link) {
zs_article <- read_html(link, encoding = "GB18030") # read the html
zs_title <- html_nodes(zs_article, "h1") %>%
html_text
zs_time <- html_nodes(zs_article, ".box01 .fl") %>%
html_text %>%
str_extract("\\d{4}年\\d{2}月\\d{2}日")
zs_content <- html_nodes(zs_article, "#rwb_zw p") %>%
html_text %>%
str_c(collapse = "") %>% # combined the paragraphs
str_remove_all("\\s|\\n|\\t") # remove the horizontal spaces
zs_data <- data.frame(title = zs_title,
time = zs_time,
content = zs_content) %>%
mutate(
time = str_replace(time, "(\\d{4})年(\\d{2})月(\\d{2})日", "\\1-\\2-\\3"),
time = as.Date(time)
)
})
ls_zhongsheng <- read_html("http://politics.people.com.cn/GB/8198/426918/index.html") %>% # index page
html_nodes("h5 a") %>% # the nodes of the links
html_attr("href") %>% # just the links
str_replace("^/n1", "http://politics.people.com.cn/n1")
df_zhongsheng <- map_df(ls_zhongsheng, function(link) {
zs_article <- read_html(link, encoding = "GB18030") # read the html
zs_title <- html_nodes(zs_article, "h1") %>%
html_text
zs_time <- html_nodes(zs_article, ".box01 .fl") %>%
html_text %>%
str_extract("\\d{4}年\\d{2}月\\d{2}日")
zs_content <- html_nodes(zs_article, "#rwb_zw p") %>%
html_text %>%
str_c(collapse = "") %>% # combined the paragraphs
str_remove_all("\\s|\\n|\\t") # remove the horizontal spaces
zs_data <- data.frame(title = zs_title,
time = zs_time,
content = zs_content) %>%
mutate(
time = str_replace(time, "(\\d{4})年(\\d{2})月(\\d{2})日", "\\1-\\2-\\3"),
time = as.Date(time)
)
})
df_zhongsheng <- map_df(ls_zhongsheng, function(link) {
zs_article <- read_html(link, encoding = "GB18030") # read the html
zs_title <- html_nodes(zs_article, "h1") %>%
html_text
zs_time <- html_nodes(zs_article, ".box01 .fl") %>%
html_text %>%
str_extract("\\d{4}年\\d{2}月\\d{2}日")
zs_content <- html_nodes(zs_article, "#rwb_zw p") %>%
html_text %>%
str_c(collapse = "") %>% # combined the paragraphs
str_remove_all("\\s|\\n|\\t") # remove the horizontal spaces
zs_data <- data.frame(title = zs_title,
time = zs_time,
content = zs_content) %>%
mutate(
time = str_replace(time, "(\\d{4})年(\\d{2})月(\\d{2})日", "\\1-\\2-\\3"),
time = as.Date(time)
)
})
ls_zhongsheng <- read_html("http://politics.people.com.cn/GB/8198/426918/index.html") %>% # index page
html_nodes("h5 a") %>% # the nodes of the links
html_attr("href") %>% # just the links
str_replace("^/n1", "http://politics.people.com.cn/n1")
df_zhongsheng <- map_df(ls_zhongsheng, function(link) {
zs_article <- read_html(link, encoding = "GB18030") # read the html
zs_title <- html_nodes(zs_article, "h1") %>%
html_text
zs_time <- html_nodes(zs_article, ".box01 .fl") %>%
html_text %>%
str_extract("\\d{4}年\\d{2}月\\d{2}日")
zs_content <- html_nodes(zs_article, "#rwb_zw p") %>%
html_text %>%
str_c(collapse = "") %>% # combined the paragraphs
str_remove_all("\\s|\\n|\\t") # remove the horizontal spaces
zs_data <- data.frame(title = zs_title,
time = zs_time,
content = zs_content) %>%
mutate(
time = str_replace(time, "(\\d{4})年(\\d{2})月(\\d{2})日", "\\1-\\2-\\3"),
time = as.Date(time)
)
})
map_df(ls_zhongsheng, function(link) {
zs_article <- read_html(link, encoding = "GB18030") # read the html
zs_title <- html_nodes(zs_article, "h1") %>%
html_text
zs_time <- html_nodes(zs_article, ".box01 .fl") %>%
html_text %>%
str_extract("\\d{4}年\\d{2}月\\d{2}日")
zs_content <- html_nodes(zs_article, "#rwb_zw p") %>%
html_text %>%
str_c(collapse = "") %>% # combined the paragraphs
str_remove_all("\\s|\\n|\\t") # remove the horizontal spaces
zs_data <- data.frame(title = zs_title,
time = zs_time,
content = zs_content) %>%
mutate(
time = str_replace(time, "(\\d{4})年(\\d{2})月(\\d{2})日", "\\1-\\2-\\3"),
time = as.Date(time)
)
})
ls_zhongsheng
ls_zhongsheng <- read_html("http://politics.people.com.cn/GB/8198/426918/index.html") %>% # index page
html_nodes("h5 a") %>% # the nodes of the links
html_attr("href") %>% # just the links
str_replace("^/n1", "http://politics.people.com.cn/n1")
map_df(ls_zhongsheng, function(link) {
zs_article <- read_html(link, encoding = "GB18030") # read the html
zs_title <- html_nodes(zs_article, "h1") %>%
html_text
zs_time <- html_nodes(zs_article, ".box01 .fl") %>%
html_text %>%
str_extract("\\d{4}年\\d{2}月\\d{2}日")
zs_content <- html_nodes(zs_article, "#rwb_zw p") %>%
html_text %>%
str_c(collapse = "") %>% # combined the paragraphs
str_remove_all("\\s|\\n|\\t") # remove the horizontal spaces
zs_data <- data.frame(title = zs_title,
time = zs_time,
content = zs_content) %>%
mutate(
time = str_replace(time, "(\\d{4})年(\\d{2})月(\\d{2})日", "\\1-\\2-\\3"),
time = as.Date(time)
)
})
df_zhongsheng <- map_df(ls_zhongsheng, function(link) {
zs_article <- read_html(link, encoding = "GB18030") # read the html
zs_title <- html_nodes(zs_article, "h1") %>%
html_text
zs_time <- html_nodes(zs_article, ".box01 .fl") %>%
html_text %>%
str_extract("\\d{4}年\\d{2}月\\d{2}日")
zs_content <- html_nodes(zs_article, "#rwb_zw p") %>%
html_text %>%
str_c(collapse = "") %>% # combined the paragraphs
str_remove_all("\\s|\\n|\\t") # remove the horizontal spaces
zs_data <- data.frame(title = zs_title,
time = zs_time,
content = zs_content) %>%
mutate(
time = str_replace(time, "(\\d{4})年(\\d{2})月(\\d{2})日", "\\1-\\2-\\3"),
time = as.Date(time)
)
})
ls_zhongsheng <- read_html("http://politics.people.com.cn/GB/8198/426918/index.html") %>% # index page
html_nodes("h5 a") %>% # the nodes of the links
html_attr("href") %>% # just the links
str_replace("^/n1", "http://politics.people.com.cn/n1")
ls_zhongsheng <- read_html("http://politics.people.com.cn/GB/8198/426918/index.html") %>% # index page
html_nodes("h5 a") %>% # the nodes of the links
html_attr("href") %>% # just the links
str_replace("^/n1", "http://politics.people.com.cn/n1")
read_html("http://politics.people.com.cn/GB/8198/426918/index.html") %>% # index page
html_nodes("h5 a") %>% # the nodes of the links
html_attr("href") %>% # just the links
str_replace("^/n1", "http://politics.people.com.cn/n1")
map_df(ls_zhongsheng, function(link) {
zs_article <- read_html(link, encoding = "GB18030") # read the html
zs_title <- html_nodes(zs_article, "h1") %>%
html_text
zs_time <- html_nodes(zs_article, ".box01 .fl") %>%
html_text %>%
str_extract("\\d{4}年\\d{2}月\\d{2}日")
zs_content <- html_nodes(zs_article, "#rwb_zw p") %>%
html_text %>%
str_c(collapse = "") %>% # combined the paragraphs
str_remove_all("\\s|\\n|\\t") # remove the horizontal spaces
zs_data <- data.frame(title = zs_title,
time = zs_time,
content = zs_content) %>%
mutate(
time = str_replace(time, "(\\d{4})年(\\d{2})月(\\d{2})日", "\\1-\\2-\\3"),
time = as.Date(time)
)
})
read_html("http://politics.people.com.cn/GB/8198/426918/index.html") %>% # index page
html_nodes("h5 a") %>% # the nodes of the links
html_attr("href") %>% # just the links
str_replace("^/n1", "http://politics.people.com.cn/n1")
ls_zhongsheng <- read_html("http://politics.people.com.cn/GB/8198/426918/index.html") %>% # index page
html_nodes("h5 a") %>% # the nodes of the links
html_attr("href") %>% # just the links
str_replace("^/n1", "http://politics.people.com.cn/n1")
ead_html("http://politics.people.com.cn/GB/8198/426918/index.html") %>% # index page
html_nodes("h5 a") %>% # the nodes of the links
html_attr("href") %>% # just the links
str_replace("^/n1", "http://politics.people.com.cn/n1")
read_html("http://politics.people.com.cn/GB/8198/426918/index.html") %>% # index page
html_nodes("h5 a") %>% # the nodes of the links
html_attr("href") %>% # just the links
str_replace("^/n1", "http://politics.people.com.cn/n1")
ls_zhongsheng <- read_html("http://politics.people.com.cn/GB/8198/426918/index.html") %>% # index page
html_nodes("h5 a") %>% # the nodes of the links
html_attr("href") %>% # just the links
str_replace("^/n1", "http://politics.people.com.cn/n1")
df_zhongsheng <- map_df(ls_zhongsheng, function(link) {
zs_article <- read_html(link, encoding = "GB18030") # read the html
zs_title <- html_nodes(zs_article, "h1") %>%
html_text
zs_time <- html_nodes(zs_article, ".box01 .fl") %>%
html_text %>%
str_extract("\\d{4}年\\d{2}月\\d{2}日")
zs_content <- html_nodes(zs_article, "#rwb_zw p") %>%
html_text %>%
str_c(collapse = "") %>% # combined the paragraphs
str_remove_all("\\s|\\n|\\t") # remove the horizontal spaces
zs_data <- data.frame(title = zs_title,
time = zs_time,
content = zs_content) %>%
mutate(
time = str_replace(time, "(\\d{4})年(\\d{2})月(\\d{2})日", "\\1-\\2-\\3"),
time = as.Date(time)
)
})
df_zhongsheng <- map_df(ls_zhongsheng, function(link) {
zs_article <- read_html(link, encoding = "GB18030") # read the html
zs_title <- html_nodes(zs_article, "h1") %>%
html_text
zs_time <- html_nodes(zs_article, ".box01 .fl") %>%
html_text %>%
str_extract("\\d{4}年\\d{2}月\\d{2}日")
zs_content <- html_nodes(zs_article, "#rwb_zw p") %>%
html_text %>%
str_c(collapse = "") %>% # combined the paragraphs
str_remove_all("\\s|\\n|\\t") # remove the horizontal spaces
zs_data <- data.frame(title = zs_title,
time = zs_time,
content = zs_content) %>%
mutate(
time = str_replace(time, "(\\d{4})年(\\d{2})月(\\d{2})日", "\\1-\\2-\\3"),
time = as.Date(time)
)
})
ls_zhongsheng <- read_html("http://politics.people.com.cn/GB/8198/426918/index.html") %>% # index page
html_nodes("h5 a") %>% # the nodes of the links
html_attr("href") %>% # just the links
str_replace("^/n1", "http://politics.people.com.cn/n1")
df_zhongsheng <- map_df(ls_zhongsheng, function(link) {
zs_article <- read_html(link, encoding = "GB18030") # read the html
zs_title <- html_nodes(zs_article, "h1") %>%
html_text
zs_time <- html_nodes(zs_article, ".box01 .fl") %>%
html_text %>%
str_extract("\\d{4}年\\d{2}月\\d{2}日")
zs_content <- html_nodes(zs_article, "#rwb_zw p") %>%
html_text %>%
str_c(collapse = "") %>% # combined the paragraphs
str_remove_all("\\s|\\n|\\t") # remove the horizontal spaces
zs_data <- data.frame(title = zs_title,
time = zs_time,
content = zs_content) %>%
mutate(
time = str_replace(time, "(\\d{4})年(\\d{2})月(\\d{2})日", "\\1-\\2-\\3"),
time = as.Date(time)
)
})
df_zhongsheng <- map_df(ls_zhongsheng, function(link) {
zs_article <- read_html(link, encoding = "GB18030") # read the html
zs_title <- html_nodes(zs_article, "h1") %>%
html_text
zs_time <- html_nodes(zs_article, ".box01 .fl") %>%
html_text %>%
str_extract("\\d{4}年\\d{2}月\\d{2}日")
zs_content <- html_nodes(zs_article, "#rwb_zw p") %>%
html_text %>%
str_c(collapse = "") %>% # combined the paragraphs
str_remove_all("\\s|\\n|\\t") # remove the horizontal spaces
zs_data <- data.frame(title = zs_title,
time = zs_time,
content = zs_content) %>%
mutate(
time = str_replace(time, "(\\d{4})年(\\d{2})月(\\d{2})日", "\\1-\\2-\\3"),
time = as.Date(time)
)
})
ls_zhongsheng <- read_html("http://politics.people.com.cn/GB/8198/426918/index.html") %>% # index page
html_nodes("h5 a") %>% # the nodes of the links
html_attr("href") %>% # just the links
str_replace("^/n1", "http://politics.people.com.cn/n1")
df_zhongsheng <- map_df(ls_zhongsheng, function(link) {
zs_article <- read_html(link, encoding = "GB18030") # read the html
zs_title <- html_nodes(zs_article, "h1") %>%
html_text
zs_time <- html_nodes(zs_article, ".box01 .fl") %>%
html_text %>%
str_extract("\\d{4}年\\d{2}月\\d{2}日")
zs_content <- html_nodes(zs_article, "#rwb_zw p") %>%
html_text %>%
str_c(collapse = "") %>% # combined the paragraphs
str_remove_all("\\s|\\n|\\t") # remove the horizontal spaces
zs_data <- data.frame(title = zs_title,
time = zs_time,
content = zs_content) %>%
mutate(
time = str_replace(time, "(\\d{4})年(\\d{2})月(\\d{2})日", "\\1-\\2-\\3"),
time = as.Date(time)
)
})
map_df(ls_zhongsheng, function(link) {
zs_article <- read_html(link, encoding = "GB18030") # read the html
zs_title <- html_nodes(zs_article, "h1") %>%
html_text
zs_time <- html_nodes(zs_article, ".box01 .fl") %>%
html_text %>%
str_extract("\\d{4}年\\d{2}月\\d{2}日")
zs_content <- html_nodes(zs_article, "#rwb_zw p") %>%
html_text %>%
str_c(collapse = "") %>% # combined the paragraphs
str_remove_all("\\s|\\n|\\t") # remove the horizontal spaces
zs_data <- data.frame(title = zs_title,
time = zs_time,
content = zs_content) %>%
mutate(
time = str_replace(time, "(\\d{4})年(\\d{2})月(\\d{2})日", "\\1-\\2-\\3"),
time = as.Date(time)
)
})
map_df(ls_zhongsheng, function(link) {
zs_article <- read_html(link, encoding = "GB18030") # read the html
zs_title <- html_nodes(zs_article, "h1") %>%
html_text
zs_time <- html_nodes(zs_article, ".box01 .fl") %>%
html_text %>%
str_extract("\\d{4}年\\d{2}月\\d{2}日")
zs_content <- html_nodes(zs_article, "#rwb_zw p") %>%
html_text %>%
str_c(collapse = "") %>% # combined the paragraphs
str_remove_all("\\s|\\n|\\t") # remove the horizontal spaces
zs_data <- data.frame(title = zs_title,
time = zs_time,
content = zs_content) %>%
mutate(
time = str_replace(time, "(\\d{4})年(\\d{2})月(\\d{2})日", "\\1-\\2-\\3"),
time = as.Date(time)
)
})
ls_zhongsheng <- read_html("http://politics.people.com.cn/GB/8198/426918/index.html") %>% # index page
html_nodes("h5 a") %>% # the nodes of the links
html_attr("href") %>% # just the links
str_replace("^/n1", "http://politics.people.com.cn/n1")
map_df(ls_zhongsheng, function(link) {
zs_article <- read_html(link, encoding = "GB18030") # read the html
zs_title <- html_nodes(zs_article, "h1") %>%
html_text
zs_time <- html_nodes(zs_article, ".box01 .fl") %>%
html_text %>%
str_extract("\\d{4}年\\d{2}月\\d{2}日")
zs_content <- html_nodes(zs_article, "#rwb_zw p") %>%
html_text %>%
str_c(collapse = "") %>% # combined the paragraphs
str_remove_all("\\s|\\n|\\t") # remove the horizontal spaces
zs_data <- data.frame(title = zs_title,
time = zs_time,
content = zs_content) %>%
mutate(
time = str_replace(time, "(\\d{4})年(\\d{2})月(\\d{2})日", "\\1-\\2-\\3"),
time = as.Date(time)
)
})
map_df(ls_zhongsheng, function(link) {
zs_article <- read_html(link, encoding = "GB18030") # read the html
zs_title <- html_nodes(zs_article, "h1") %>%
html_text
zs_time <- html_nodes(zs_article, ".box01 .fl") %>%
html_text %>%
str_extract("\\d{4}年\\d{2}月\\d{2}日")
zs_content <- html_nodes(zs_article, "#rwb_zw p") %>%
html_text %>%
str_c(collapse = "") %>% # combined the paragraphs
str_remove_all("\\s|\\n|\\t") # remove the horizontal spaces
zs_data <- data.frame(title = zs_title,
time = zs_time,
content = zs_content) %>%
mutate(
time = str_replace(time, "(\\d{4})年(\\d{2})月(\\d{2})日", "\\1-\\2-\\3"),
time = as.Date(time)
)
})
function(link) {
zs_article <- read_html(link, encoding = "GB18030") # read the html
zs_title <- html_nodes(zs_article, "h1") %>%
html_text
zs_time <- html_nodes(zs_article, ".box01 .fl") %>%
html_text %>%
str_extract("\\d{4}年\\d{2}月\\d{2}日")
zs_content <- html_nodes(zs_article, "#rwb_zw p") %>%
html_text %>%
str_c(collapse = "") %>% # combined the paragraphs
str_remove_all("\\s|\\n|\\t") # remove the horizontal spaces
zs_data <- data.frame(title = zs_title,
time = zs_time,
content = zs_content) %>%
mutate(
time = str_replace(time, "(\\d{4})年(\\d{2})月(\\d{2})日", "\\1-\\2-\\3"),
time = as.Date(time)
)
}
